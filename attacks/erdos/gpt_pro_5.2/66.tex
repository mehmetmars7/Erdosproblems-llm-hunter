% Solutions for selected Erd\H{o}s problems (66--75)
% Source problems: 66-75.tex
% This file was generated to follow the OUTPUT FORMAT in PROMPT_STRATEGY.MD.

% Erd\H{o}s Problem #66

\noindent\textbf{FORMAL RESTATEMENT.}
Let $\mathbb N:=\{1,2,3,\dots\}$. For $A\subseteq\mathbb N$ define the indicator $1_A:\mathbb Z\to\{0,1\}$ by $1_A(m)=1$ if $m\in A$ and $0$ otherwise. For $n\ge 2$ define
\[
(1_A\ast 1_A)(n)
:=\sum_{k=1}^{n-1} 1_A(k)\,1_A(n-k).
\]
Equivalently, $(1_A\ast 1_A)(n)$ counts \emph{ordered} pairs $(a,b)\in A\times A$ with $a+b=n$.
(If one instead takes $\mathbb N=\{0,1,2,\dots\}$, then the above sum changes by at most $O(1)$ for each fixed $n$, which does not affect the existence/value of $\lim_{n\to\infty}(1_A\ast 1_A)(n)/\log n$.)

Question: does there exist $A\subseteq\mathbb N$ such that the limit
\[
L:=\lim_{n\to\infty} \frac{(1_A\ast 1_A)(n)}{\log n}
\]
exists as a finite real number and satisfies $L\neq 0$? Here $\log$ is the natural logarithm.

\medskip
\noindent\textbf{QUICK LITERATURE/CONTEXT CHECK.}
The problem statement notes:
(i) a suitably constructed random set can have $(1_A\ast 1_A)(n)/\log n$ convergent off an exceptional set of density $0$, but the challenge is removing the exceptional set;
(ii) Erd\H{o}s believed the answer should be negative;
(iii) Erd\H{o}s--S\'{a}rk\"{o}zy proved it is impossible to have $\lvert (1_A\ast 1_A)(n)-\log n\rvert/\sqrt{\log n}\to 0$;
(iv) Horv\'{a}th proved that $\lvert (1_A\ast 1_A)(n)-\log n\rvert\le (1-\epsilon)\sqrt{\log n}$ cannot hold for all large $n$.
No additional results are used here.

\medskip
\noindent\textbf{ATTACK PLAN.}
\emph{Proof track ideas.}
(1) Probabilistic model: choose $m\in A$ independently with probability $p_m\approx \sqrt{\log m/m}$, for which $\mathbb E(1_A\ast 1_A)(n)$ is of order $\log n$; then attempt a concentration/Borel--Cantelli argument to force $(1_A\ast 1_A)(n)= (L+o(1))\log n$ \emph{for all} large $n$ (no exceptional set), and then derandomize.
(2) Constructive/greedy model: build $A$ inductively to keep $(1_A\ast 1_A)(n)$ near a target profile for all $n\le N$, and attempt to control long-range effects.

\emph{Disproof track ideas.}
(1) Prove unavoidable oscillation: show $\liminf (1_A\ast 1_A)(n)/\log n$ and $\limsup (1_A\ast 1_A)(n)/\log n$ are separated by an absolute constant for every $A$.
(2) Show that any attempt to enforce convergence forces contradictions in additive structure (e.g., via energy/Fourier methods).

I did not reach a complete proof or counterexample; below are problem-specific structural lemmas and computations.

\medskip
\noindent\textbf{WORK.}

\medskip
\noindent\textbf{Lemma 66.1 (pair-count sandwich).}
For $A\subseteq\mathbb N$ define $A(x):=\lvert A\cap[1,x]\rvert$ for real $x\ge 1$. Then for every integer $N\ge 1$,
\[
A(N)^2\ \le\ \sum_{n=2}^{2N} (1_A\ast 1_A)(n)\ \le\ A(2N)^2.
\]

\noindent\textbf{Proof.}
The sum $\sum_{n=2}^{2N} (1_A\ast 1_A)(n)$ counts ordered pairs $(a,b)\in A\times A$ with $a+b\le 2N$ (each pair contributes exactly once, at $n=a+b$).

\emph{Lower bound.}
Every ordered pair $(a,b)$ with $a\le N$ and $b\le N$ satisfies $a+b\le 2N$, hence is counted. The number of such ordered pairs is $A(N)^2$. Therefore
$A(N)^2\le \sum_{n=2}^{2N} (1_A\ast 1_A)(n)$.

\emph{Upper bound.}
If an ordered pair $(a,b)\in A\times A$ satisfies $a+b\le 2N$ and $a,b\in\mathbb N$, then necessarily $a\le 2N$ and $b\le 2N$. Hence all counted pairs lie in $(A\cap[1,2N])\times(A\cap[1,2N])$, whose size is $A(2N)^2$. Thus
$\sum_{n=2}^{2N} (1_A\ast 1_A)(n)\le A(2N)^2$.
This proves the lemma.\hfill$\square$

\medskip
\noindent\textbf{Corollary 66.1.}
Assume there exists $L\in(0,\infty)$ such that
\[\lim_{n\to\infty}\frac{(1_A\ast 1_A)(n)}{\log n}=L.\]
Then there exist constants $c,C>0$ (depending only on $L$) such that for all sufficiently large $X$,
\[
 c\,\sqrt{X\log X}\ \le\ A(X)\ \le\ C\,\sqrt{X\log X}.
\]

\noindent\textbf{Proof.}
Choose $\eta\in(0,1/2)$. For all sufficiently large $n$ we have
\[(L-\eta)\log n\le (1_A\ast 1_A)(n)\le (L+\eta)\log n.\]
Fix large $N$ so that these bounds hold for every $n\in[N,2N]$.

\emph{Upper bound on $A(N)$.}
By Lemma 66.1,
\[
A(N)^2\le \sum_{n=2}^{2N}(1_A\ast 1_A)(n)
=O(1)+\sum_{n=N}^{2N}(1_A\ast 1_A)(n)
\le O(1)+(L+\eta)\sum_{n=N}^{2N}\log n.
\]
Since $\sum_{n=N}^{2N}\log n\le N\log(2N)$, it follows that
$A(N)^2\le (L+\eta)N\log(2N)+O(1)$, hence for large $N$,
\[A(N)\le \sqrt{2(L+\eta)}\,\sqrt{N\log N}.
\]

\emph{Lower bound on $A(2N)$.}
Again by Lemma 66.1,
\[
A(2N)^2\ge \sum_{n=2}^{2N}(1_A\ast 1_A)(n)
\ge \sum_{n=N}^{2N}(1_A\ast 1_A)(n)
\ge (L-\eta)\sum_{n=N}^{2N}\log n.
\]
Also $\sum_{n=N}^{2N}\log n\ge N\log N$. Therefore $A(2N)^2\ge (L-\eta)N\log N$, i.e.
\[A(2N)\ge \sqrt{L-\eta}\,\sqrt{N\log N}.
\]
Renaming $X=2N$ and absorbing constants into $c,C$ yields the claim.\hfill$\square$

\medskip
\noindent\textbf{Lemma 66.2 (a random model with $\mathbb E(1_A\ast 1_A)(n)\asymp\log n$).}
Fix $p_m:=\min\{1,\sqrt{\log m/m}\}$ for integers $m\ge 3$, and set $p_1=p_2=0$. Let $A$ be a random subset of $\mathbb N$ where the events $\{m\in A\}$ are independent and $\mathbb P(m\in A)=p_m$. Let
\[R(n):=(1_A\ast 1_A)(n)=\sum_{k=1}^{n-1}1_A(k)1_A(n-k).\]
Then
\[\mathbb E R(n)=\pi\log n + O(1)\qquad (n\to\infty).\]

\noindent\textbf{Proof.}
By independence,
\[\mathbb E R(n)=\sum_{k=1}^{n-1} \mathbb E[1_A(k)]\,\mathbb E[1_A(n-k)] = \sum_{k=1}^{n-1} p_k p_{n-k}.
\]
Only finitely many $k$ have $p_k=1$ (indeed $\sqrt{\log k/k}<1$ for all sufficiently large $k$), so replacing $p_k$ by $\sqrt{\log k/k}$ changes the sum by at most an absolute $O(1)$. Thus it suffices to analyze
\[
S(n):=\sum_{k=3}^{n-3} \frac{\sqrt{\log k\,\log(n-k)}}{\sqrt{k(n-k)}}.
\]

\emph{Step 1: discard the extreme ranges.}
Let $M:=\lfloor n^{2/3}\rfloor$. For $3\le k\le M$ we have $n-k\ge n/2$ for $n$ large, hence
\[
\frac{\sqrt{\log k\,\log(n-k)}}{\sqrt{k(n-k)}}
\le \frac{\log n}{\sqrt{k\, (n/2)}}
= \sqrt{\frac{2}{n}}\,\frac{\log n}{\sqrt{k}}.
\]
Therefore
\[
\sum_{k=3}^{M}\frac{\sqrt{\log k\,\log(n-k)}}{\sqrt{k(n-k)}}
\le \sqrt{\frac{2}{n}}\,\log n\sum_{k=3}^{M}k^{-1/2}
\le \sqrt{\frac{2}{n}}\,\log n\cdot 2\sqrt{M}
\ll (\log n)\,n^{-1/6},
\]
which is $o(1)$ and in particular $O(1)$. By symmetry, the same bound holds for the range $n-M\le k\le n-3$. Hence the contribution of the two extreme ranges is $O(1)$.

\emph{Step 2: main range as a Riemann sum.}
Consider the middle range $k\in[M,\,n-M]$. In this range, $k$ and $n-k$ are both between $n^{2/3}$ and $n$, so
\[\log k = \log n + O(1),\qquad \log(n-k)=\log n + O(1).
\]
Consequently,
\[\sqrt{\log k\,\log(n-k)} = \log n + O(1)
\]
uniformly for $k\in[M,n-M]$. Thus
\[
S(n)=(\log n)\sum_{k=M}^{n-M}\frac{1}{\sqrt{k(n-k)}}
+O\Big(\sum_{k=M}^{n-M}\frac{1}{\sqrt{k(n-k)}}\Big)+O(1).
\]
We now analyze
\[
T(n):=\sum_{k=1}^{n-1}\frac{1}{\sqrt{k(n-k)}}.
\]
Write $x_k:=k/n$. Then
\[
T(n)=\frac1n\sum_{k=1}^{n-1}\frac{1}{\sqrt{x_k(1-x_k)}}.
\]
The function $f(x):=1/\sqrt{x(1-x)}$ is integrable on $(0,1)$ and continuous away from $0,1$, so the above is a Riemann sum converging to $\int_0^1 f(x)\,dx$. Moreover, truncating the endpoints at $x\in[n^{-1/3},1-n^{-1/3}]$ changes the sum by $O(n^{-1/6})$ (the same estimate as in Step 1). Therefore
\[
\sum_{k=M}^{n-M}\frac{1}{\sqrt{k(n-k)}} = \int_0^1\frac{dx}{\sqrt{x(1-x)}} + o(1).
\]
A standard substitution $x=\sin^2\theta$ gives
\[
\int_0^1\frac{dx}{\sqrt{x(1-x)}}=\int_0^{\pi/2} 2\,d\theta = \pi.
\]
Hence $\sum_{k=M}^{n-M} 1/\sqrt{k(n-k)} = \pi + o(1)$, and also the same sum is $O(1)$. Plugging into the expression for $S(n)$ yields
\[S(n)=\pi\log n + O(1).
\]
As noted at the start, $\mathbb E R(n)=S(n)+O(1)$, so $\mathbb E R(n)=\pi\log n+O(1)$ as claimed.\hfill$\square$

\medskip
\noindent\textbf{FAST REALITY CHECK (computation).}
I simulated the above random model up to $N=20000$ (sampling each $m\le N$ independently with $p_m=\sqrt{\log m/m}$, capped at $1$; using FFT to compute $(1_A\ast 1_A)(n)$ for $n\le N$).
In one fixed sample (random seed $0$):
\begin{itemize}
\item $\lvert A\cap[1,N]\rvert = 838$.
\item For $n\in[1000,20000]$, the ratios $(1_A\ast 1_A)(n)/\log n$ had
\[\text{mean }\approx 2.83406,\quad \text{std }\approx 0.77861,\quad \min\approx 0.24871,\quad \max\approx 6.33715.\]
\item Empirical quantiles of $(1_A\ast 1_A)(n)/\log n$ over $n\in[1000,20000]$:
\[\begin{array}{l}
1\%:~1.17604,\quad 5\%:~1.61628,\quad 10\%:~1.85266,\\
50\%:~2.80917,\quad 90\%:~3.85182,\quad 95\%:~4.16215,\quad 99\%:~4.74097.
\end{array}\]
\end{itemize}
These data are consistent with $\mathbb E(1_A\ast 1_A)(n)\asymp\log n$ but show large fluctuations at this scale; they do \emph{not} demonstrate convergence for all $n$.

\medskip
\noindent\textbf{VERIFICATION.}
\begin{itemize}
\item Lemma 66.1: checked both inequalities by explicit pair-counting; the bounds use only $a+b\le 2N\Rightarrow a,b\le 2N$ and the fact that each ordered pair contributes to exactly one $n$.
\item Corollary 66.1: the dyadic renaming $X=2N$ is the only place constants change; all uses of $\log n$ are for $n$ sufficiently large.
\item Lemma 66.2: the endpoint contributions were bounded by a direct comparison to $\sum k^{-1/2}$; the main term uses a Riemann-sum limit to the integral $\int_0^1 dx/\sqrt{x(1-x)}=\pi$.
\item Computation: for $n\le N$ the convolution uses only sampled values $1_A(k)$ for $k\le n-1\le N-1$, so truncation at $N$ does not affect $(1_A\ast 1_A)(n)$ for $n\le N$.
\end{itemize}

\medskip
\noindent\textbf{FINAL: \textbf{UNRESOLVED}.}
\begin{itemize}
\item[(i)] \emph{Strongest proved partial result.} If the limit $\lim_{n\to\infty}(1_A\ast 1_A)(n)/\log n=L\in(0,\infty)$ exists, then the counting function satisfies $A(X)=\Theta(\sqrt{X\log X})$ (Corollary 66.1). Also, in a natural independent random model with $\mathbb P(m\in A)\approx\sqrt{\log m/m}$ one has $\mathbb E(1_A\ast 1_A)(n)=\pi\log n+O(1)$ (Lemma 66.2).
\item[(ii)] \emph{First gap (crisp).} Establish (or refute) that there exists \,a\, deterministic $A\subseteq\mathbb N$ and $L\neq 0$ such that
\[ (1_A\ast 1_A)(n)= (L+o(1))\log n\quad\text{for \emph{every} integer }n\to\infty,\]
with no exceptional set.
\item[(iii)] \emph{Top 3 next moves.}
(1) Prove a uniform concentration estimate for the random model: show $\sum_n \mathbb P(|R(n)-\mathbb ER(n)|>\varepsilon\log n)<\infty$ for some $\varepsilon>0$ (or show this fails), enabling Borel--Cantelli to give an almost-sure statement for all large $n$.
(2) Attempt a derandomization (e.g., via the probabilistic method/alterations) that fixes all large $n$ simultaneously rather than outside a density-$0$ set.
(3) On the disproof side, try to prove an oscillation lower bound: show there is an absolute $c_0>0$ such that for every $A$, $\limsup\frac{(1_A\ast 1_A)(n)}{\log n}-\liminf\frac{(1_A\ast 1_A)(n)}{\log n}\ge c_0$.
\item[(iv)] \emph{Minimal counterexample structure.} If a positive-limit example exists, it must have $A(X)\asymp \sqrt{X\log X}$ and a representation function with unusually small relative fluctuations: for dyadic ranges $[N,2N]$, almost all of the $\Theta(N\log N)$ ordered sums from $A\cap[1,2N]$ would need to be spread with near-logarithmic regularity across the $N$ possible target sums.
\end{itemize}


